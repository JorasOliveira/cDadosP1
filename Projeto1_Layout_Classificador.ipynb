{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Diogo dos Reis Duarte\n",
    "\n",
    "Nome: Jorás Custodio Campos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção: Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in d:\\anaconda-python\\lib\\site-packages (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "!pip install emoji\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import emoji\n",
    "from emoji import UNICODE_EMOJI\n",
    "import functools\n",
    "import operator\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diretório\n",
      "C:\\Users\\Lava Boy 2.0\\Desktop\\Desktop\\Insper\\2-semestrePt2\\cdados\\CdadosProjeto1\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diretório')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo PS5.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'PS5.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@bossupbaby_ if you still need a ps5, i got mi...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ketan_patel07 @target same! i’m still mad the...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my brother got himself a ps5... consider me je...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>silent hill’s keiichiro toyama is working with...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@awesomejon21 bruh 20 on the ps5 will make you...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento Classificação\n",
       "0  @bossupbaby_ if you still need a ps5, i got mi...             P\n",
       "1  @ketan_patel07 @target same! i’m still mad the...             R\n",
       "2  my brother got himself a ps5... consider me je...             R\n",
       "3  silent hill’s keiichiro toyama is working with...             I\n",
       "4  @awesomejon21 bruh 20 on the ps5 will make you...             P"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waited 4 months for the ps5 controller chargin...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mattswider thanks to you my ps5 finally came ...</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all accessories up on playstation direct....co...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@mk2true you got any ps5 kicking about..</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@romudeth i want sony to compete with bringing...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste Classificação\n",
       "0  waited 4 months for the ps5 controller chargin...             R\n",
       "1  @mattswider thanks to you my ps5 finally came ...             I\n",
       "2  all accessories up on playstation direct....co...             P\n",
       "3           @mk2true you got any ps5 kicking about..             I\n",
       "4  @romudeth i want sony to compete with bringing...             R"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "O produto a ser analisado será o novo console da Sony, o Playstation 5. Ao analisar os tweets, conseguimos encontrar 3 padrões, os quais avaliamos os nossos tweets. Estes foram (R) de relevante, que são tweets que trazem discussões e opiniões a cerca do produto, (P) de pouco relevante, que são os tweets que fazem propagandas do produto junto com outros itens adjacentes, como por exemplo acessórios (fones, headset, controles) ou jogos, ou tweets que se remetem a vendas a cerca do produto, e (I) de irrelevante, que são tweets que não se encaixam nos padrões mencionados, ou que simplesmente não fala do produto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_emoji(text): #separa emojis dos outros caracteres\n",
    "    return ''.join(' ' + char if char in UNICODE_EMOJI else char for char in text).strip() #caso seja um emoji, adiciona um espaco, caso nao seja, apenas retorna a letra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [\",\", \"'\", '\"', \".\", \"!\", \"?\", \";\", \":\", \"[\", \"]\",\"{\", \"}\", \"(\", \")\", \"#\", \"/\",  \"\\\\\", \"https\",\"+\", \"@\", \"*\", \"-\"] \n",
    "word_count = dict()\n",
    "total = 0 #total de palavras no banco de dados\n",
    "\n",
    "train.Classificação = train.Classificação.apply(lambda x: x.upper())\n",
    "for i, tweet in train.iterrows(): #iterando a base de dados\n",
    "    piu = tweet.Treinamento #carregando apenas os tweets\n",
    "    \n",
    "    for c in chars: #iterando a listad e cacarteres p/ remover\n",
    "        piu = piu.replace(c, \" \") #trocando os caracteres por \" \"\n",
    "        \n",
    "    for word in separate_emoji(piu).split(): #splitando os tweets em palavras e emojis separadamente\n",
    "        word_count[word] = word_count.get(word, {'I':0, 'P':0, 'R':0}) #garantindo que  a palavra existe no dicionario, caso nao exista ela eh criada\n",
    "        word_count[word][tweet.Classificação] += 1 #incrementando o contador do valor correto\n",
    "        total += 1\n",
    "        \n",
    "I = {word: word_count[word]['I'] for word in word_count if word_count[word]['I'] > 0} #I contem todas as palavras Irrelevantes, seu sum(I.values) == total de palavras Irrelevantes\n",
    "P = {word: word_count[word]['P'] for word in word_count if word_count[word]['P'] > 0} #P contem todas as palavras Pouco relevantes, seu sum(P.values) == total de palavras Pouco relevantes\n",
    "R = {word: word_count[word]['R'] for word in word_count if word_count[word]['R'] > 0} #R contem todas as palavras Relevantes, seu sum(R.values) == total de palavras Relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda-Python\\lib\\site-packages\\ipykernel_launcher.py:50: RuntimeWarning: overflow encountered in longlong_scalars\n",
      "D:\\anaconda-Python\\lib\\site-packages\\ipykernel_launcher.py:55: RuntimeWarning: overflow encountered in longlong_scalars\n",
      "D:\\anaconda-Python\\lib\\site-packages\\ipykernel_launcher.py:45: RuntimeWarning: overflow encountered in longlong_scalars\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Classificação_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waited 4 months for the ps5 controller chargin...</td>\n",
       "      <td>R</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@mattswider thanks to you my ps5 finally came ...</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>all accessories up on playstation direct....co...</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@mk2true you got any ps5 kicking about..</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@romudeth i want sony to compete with bringing...</td>\n",
       "      <td>R</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@littlemyuri @its_menieb @xboxgamepass @xbox o...</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>god of war 4 walkthrough last part secret endi...</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@nsarmoredfrog awesome! this should to happen ...</td>\n",
       "      <td>R</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@yukomama711 split the money if ya’ll win, if ...</td>\n",
       "      <td>P</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>#demonssouls #ps5 demon's souls ps5 #ps5share,...</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@kfcgaming i’m surprised the first comment i s...</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>playstation plus - 3 month subscription uk ps4...</td>\n",
       "      <td>P</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@anthonyanyon @youtube dont fall for that ps5 ...</td>\n",
       "      <td>R</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ladies and gentlemen... we got him. #ps5 https...</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>i can’t even buy a ps5 cause of you rich assho...</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ps5 vertical stand with 2 dualsense charging d...</td>\n",
       "      <td>P</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@stebuu @swiftonsecurity the loads are ridicul...</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@economicsno @toosxope @thesitesupply good for...</td>\n",
       "      <td>P</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@vizio @viziosupport my tv is blacked out it w...</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>#live : fornite fr game abo partie perso pp #p...</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teste Classificação  \\\n",
       "0   waited 4 months for the ps5 controller chargin...             R   \n",
       "1   @mattswider thanks to you my ps5 finally came ...             I   \n",
       "2   all accessories up on playstation direct....co...             P   \n",
       "3            @mk2true you got any ps5 kicking about..             I   \n",
       "4   @romudeth i want sony to compete with bringing...             R   \n",
       "5   @littlemyuri @its_menieb @xboxgamepass @xbox o...             R   \n",
       "6   god of war 4 walkthrough last part secret endi...             P   \n",
       "7   @nsarmoredfrog awesome! this should to happen ...             R   \n",
       "8   @yukomama711 split the money if ya’ll win, if ...             P   \n",
       "9   #demonssouls #ps5 demon's souls ps5 #ps5share,...             P   \n",
       "10  @kfcgaming i’m surprised the first comment i s...             R   \n",
       "11  playstation plus - 3 month subscription uk ps4...             P   \n",
       "12  @anthonyanyon @youtube dont fall for that ps5 ...             R   \n",
       "13  ladies and gentlemen... we got him. #ps5 https...             I   \n",
       "14  i can’t even buy a ps5 cause of you rich assho...             P   \n",
       "15  ps5 vertical stand with 2 dualsense charging d...             P   \n",
       "16  @stebuu @swiftonsecurity the loads are ridicul...             R   \n",
       "17  @economicsno @toosxope @thesitesupply good for...             P   \n",
       "18  @vizio @viziosupport my tv is blacked out it w...             I   \n",
       "19  #live : fornite fr game abo partie perso pp #p...             I   \n",
       "\n",
       "   Classificação_A  \n",
       "0                I  \n",
       "1                I  \n",
       "2                P  \n",
       "3                I  \n",
       "4                P  \n",
       "5                R  \n",
       "6                P  \n",
       "7                I  \n",
       "8                I  \n",
       "9                P  \n",
       "10               R  \n",
       "11               I  \n",
       "12               I  \n",
       "13               I  \n",
       "14               P  \n",
       "15               I  \n",
       "16               R  \n",
       "17               I  \n",
       "18               I  \n",
       "19               I  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# totalR = (sum(R.values())) #total de palavaras na categoria Relevante\n",
    "# totalP = (sum(P.values())) #total de palavaras na categoria Pouco Relevante\n",
    "# totalI = (sum(I.values())) #total de palavaras na categoria Irrelevante\n",
    "\n",
    "#como ja era um dicionario previamente, nao tem a necessidade de usar o comando value.counts(True)\n",
    "tabela_relativa_R = pd.Series(R)\n",
    "\n",
    "tabela_relativa_P = pd.Series(P)\n",
    "\n",
    "tabela_relativa_I = pd.Series(I)\n",
    "\n",
    "\n",
    "\n",
    "totalR = tabela_relativa_R.size #total de palavaras na categoria Relevante\n",
    "totalP = tabela_relativa_P.size #total de palavaras na categoria Pouco Relevante\n",
    "totalI = tabela_relativa_I.size #total de palavaras na categoria Irrelevante\n",
    "\n",
    "\n",
    "#Calculando o P(P), P(R) e P(I)\n",
    "probR = totalR/total\n",
    "\n",
    "probP = totalP/total\n",
    "\n",
    "probI = totalI/total\n",
    "\n",
    "l = [] #lista de classificacoes, mesma ordem da base test\n",
    "for i, tweet in test.iterrows(): #iterando a base de dados\n",
    "    \n",
    "    #inicializamos como 1 para nao dar erro na multiplicacao\n",
    "    probTweetR = 1  \n",
    "    probTweetP = 1\n",
    "    probTweetI = 1 \n",
    "    \n",
    "    piu = tweet.Teste #carregando apenas os tweets \n",
    "    \n",
    "    for c in chars: #iterando a listad e cacarteres p/ remover\n",
    "        piu = piu.replace(c, \" \") #trocando os caracteres por \" \"\n",
    "    \n",
    "    #splitando os tweets em palavras e emojis separadamente e calculando a probalidade de cada palavra de ser cada categoria, fazendo a suavizacao de laplace\n",
    "    for word in separate_emoji(piu).split(): \n",
    "        \n",
    "        #Calculando o P(T|P), P(T|R) e P(T|I)\n",
    "        #pega o erro de palavras que nao existem em uma das tabelas\n",
    "        try: \n",
    "            probTweetR *= tabela_relativa_R[word]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try: \n",
    "            probTweetP *= tabela_relativa_P[word]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try: \n",
    "            probTweetI *= tabela_relativa_I[word]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #calculando P(P|T), P(R|T), P(I|T)\n",
    "    probTweetR = probTweetR * probR\n",
    "    \n",
    "    probTweetP = probTweetP * probP\n",
    "    \n",
    "    probTweetI = probTweetI * probI\n",
    "    \n",
    "    result = {\"R\":probTweetR,\"P\":probTweetP,\"I\": probTweetI} #dicionario para a comparacao dentro do MAX abaixo\n",
    "    l.append(max(result, key = result.get)) #compara os valores de r, p, i, e adiciona correta a lista L \n",
    "\n",
    "test[\"Classificação_A\"] = l #adiciona a coluna classificacao a test, como a ordem eh a mesma, podemos adicionar.\n",
    "\n",
    "test.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda-Python\\lib\\site-packages\\ipykernel_launcher.py:26: RuntimeWarning: overflow encountered in longlong_scalars\n",
      "D:\\anaconda-Python\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: overflow encountered in longlong_scalars\n",
      "D:\\anaconda-Python\\lib\\site-packages\\ipykernel_launcher.py:31: RuntimeWarning: overflow encountered in longlong_scalars\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Classificação_A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@bossupbaby_ if you still need a ps5, i got mi...</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@ketan_patel07 @target same! i’m still mad the...</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my brother got himself a ps5... consider me je...</td>\n",
       "      <td>R</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>silent hill’s keiichiro toyama is working with...</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@awesomejon21 bruh 20 on the ps5 will make you...</td>\n",
       "      <td>P</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.@officialteehub offers the best price on that...</td>\n",
       "      <td>I</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@askplaystation the new ps5 that i gave my son...</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@moonzugn been on twitter for years and all st...</td>\n",
       "      <td>P</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@thesitesupply you got me a ps5,  now i need a...</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@jacktheflippa probably wants a ps5 first</td>\n",
       "      <td>P</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ps5 at sears @solelinks https://t.co/qjowhhgdaw</td>\n",
       "      <td>P</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@alexac__ if you still need a ps5, i got mine ...</td>\n",
       "      <td>P</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a 42gb game is taking over an hour and a half ...</td>\n",
       "      <td>R</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@mattswider gone already. i never win. don't e...</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@fadieecurly @mattswider which ps5</td>\n",
       "      <td>I</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@mattswider got this and the remote. thanks ag...</td>\n",
       "      <td>P</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@mattswider got it! this will go well with the...</td>\n",
       "      <td>P</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>i never realized buying a ps5 would be so diff...</td>\n",
       "      <td>R</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[ps5] [1080p 60fps] first time playing crash b...</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>i officially joined ps5 gang. it’s been a hard...</td>\n",
       "      <td>P</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Treinamento Classificação  \\\n",
       "0   @bossupbaby_ if you still need a ps5, i got mi...             P   \n",
       "1   @ketan_patel07 @target same! i’m still mad the...             R   \n",
       "2   my brother got himself a ps5... consider me je...             R   \n",
       "3   silent hill’s keiichiro toyama is working with...             I   \n",
       "4   @awesomejon21 bruh 20 on the ps5 will make you...             P   \n",
       "5   .@officialteehub offers the best price on that...             I   \n",
       "6   @askplaystation the new ps5 that i gave my son...             R   \n",
       "7   @moonzugn been on twitter for years and all st...             P   \n",
       "8   @thesitesupply you got me a ps5,  now i need a...             P   \n",
       "9           @jacktheflippa probably wants a ps5 first             P   \n",
       "10    ps5 at sears @solelinks https://t.co/qjowhhgdaw             P   \n",
       "11  @alexac__ if you still need a ps5, i got mine ...             P   \n",
       "12  a 42gb game is taking over an hour and a half ...             R   \n",
       "13  @mattswider gone already. i never win. don't e...             I   \n",
       "14                 @fadieecurly @mattswider which ps5             I   \n",
       "15  @mattswider got this and the remote. thanks ag...             P   \n",
       "16  @mattswider got it! this will go well with the...             P   \n",
       "17  i never realized buying a ps5 would be so diff...             R   \n",
       "18  [ps5] [1080p 60fps] first time playing crash b...             I   \n",
       "19  i officially joined ps5 gang. it’s been a hard...             P   \n",
       "\n",
       "   Classificação_A  \n",
       "0                P  \n",
       "1                R  \n",
       "2                I  \n",
       "3                I  \n",
       "4                I  \n",
       "5                R  \n",
       "6                R  \n",
       "7                I  \n",
       "8                P  \n",
       "9                I  \n",
       "10               I  \n",
       "11               P  \n",
       "12               I  \n",
       "13               I  \n",
       "14               P  \n",
       "15               I  \n",
       "16               I  \n",
       "17               P  \n",
       "18               I  \n",
       "19               R  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [] #lista de classificacoes, mesma ordem da base test\n",
    "\n",
    "for i, tweet in train.iterrows(): #iterando a base de dados\n",
    "    \n",
    "    #inicializamos como 1 para nao dar erro na multiplicacao\n",
    "    probTweetR = 1  \n",
    "    probTweetP = 1\n",
    "    probTweetI = 1 \n",
    "    \n",
    "    piu = tweet.Treinamento #carregando apenas os tweets \n",
    "    \n",
    "    for c in chars: #iterando a lista de caracrteres p/ remover\n",
    "        piu = piu.replace(c, \" \") #trocando os caracteres por \" \"\n",
    "    \n",
    "    #splitando os tweets em palavras e emojis separadamente e calculando a probalidade de cada palavra de ser cada categoria, fazendo a suavizacao de laplace\n",
    "    for word in separate_emoji(piu).split(): \n",
    "        \n",
    "        #Calculando o P(T|P), P(T|R) e P(T|I)\n",
    "        #pega o erro de palavras que nao existem em uma das tabelas\n",
    "        try: \n",
    "            probTweetR *= tabela_relativa_R[word]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try: \n",
    "            probTweetP *= tabela_relativa_P[word]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try: \n",
    "            probTweetI *= tabela_relativa_I[word]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    #calculando P(P|T), P(R|T), P(I|T)\n",
    "    probTweetR = probTweetR * probR\n",
    "    \n",
    "    probTweetP = probTweetP * probP\n",
    "    \n",
    "    probTweetI = probTweetI * probI\n",
    "    \n",
    "    result = {\"R\":probTweetR,\"P\":probTweetP,\"I\": probTweetI} #dicionario para a comparacao dentro do MAX abaixo\n",
    "    l.append(max(result, key = result.get)) #compara os valores de r, p, i, e adiciona correta a lista L \n",
    "\n",
    "train[\"Classificação_A\"] = l #adiciona a coluna classificacao a test, como a ordem eh a mesma, podemos adicionar.\n",
    "\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P    0.396\n",
      "I    0.308\n",
      "R    0.296\n",
      "Name: Classificação, dtype: float64\n",
      "I    0.390\n",
      "P    0.356\n",
      "R    0.254\n",
      "Name: Classificação, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(test.Classificação.value_counts(normalize=True))\n",
    "print(train.Classificação.apply(lambda x: x.upper()).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificação_A</th>\n",
       "      <th>I</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificação</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>59.74026</td>\n",
       "      <td>25.97403</td>\n",
       "      <td>14.28571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>44.44444</td>\n",
       "      <td>33.33333</td>\n",
       "      <td>22.22222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>40.54054</td>\n",
       "      <td>29.72973</td>\n",
       "      <td>29.72973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificação_A         I         P         R\n",
       "Classificação                                \n",
       "I                59.74026  25.97403  14.28571\n",
       "P                44.44444  33.33333  22.22222\n",
       "R                40.54054  29.72973  29.72973"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('teste')\n",
    "(pd.crosstab(test.Classificação,test.Classificação_A, normalize = 'index')*100).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste - quantitativo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificação_A</th>\n",
       "      <th>I</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificação</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>46</td>\n",
       "      <td>20</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificação_A   I   P   R\n",
       "Classificação              \n",
       "I                46  20  11\n",
       "P                44  33  22\n",
       "R                30  22  22"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('teste - quantitativo')\n",
    "pd.crosstab(test.Classificação, test.Classificação_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinamento\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificação_A</th>\n",
       "      <th>I</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificação</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>64.10256</td>\n",
       "      <td>23.58974</td>\n",
       "      <td>12.30769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>25.28090</td>\n",
       "      <td>58.98876</td>\n",
       "      <td>15.73034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>35.43307</td>\n",
       "      <td>22.83465</td>\n",
       "      <td>41.73228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificação_A         I         P         R\n",
       "Classificação                                \n",
       "I                64.10256  23.58974  12.30769\n",
       "P                25.28090  58.98876  15.73034\n",
       "R                35.43307  22.83465  41.73228"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('treinamento')\n",
    "(pd.crosstab(train.Classificação,train.Classificação_A, normalize = 'index')*100).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinamento - quantitativo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Classificação_A</th>\n",
       "      <th>I</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificação</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>125</td>\n",
       "      <td>46</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>45</td>\n",
       "      <td>105</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>45</td>\n",
       "      <td>29</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Classificação_A    I    P   R\n",
       "Classificação                \n",
       "I                125   46  24\n",
       "P                 45  105  28\n",
       "R                 45   29  53"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('treinamento - quantitativo')\n",
    "pd.crosstab(train.Classificação, train.Classificação_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Para concluir e finalizar o projeto, vamos analisar o nosso sistema de seleção de dados. Em relação ao nosso classificador, nós vemos que comparando a nossa classificação manual com o classificador, na base de dados de treino, 66,15% dos tweets irrelevantes se manteram na mesma posição, assim como 54,49% dos pouco relevantes e 38,58% dos relevantes. Enquanto isso na base de teste, 55,84% dos tweets irrelevantes se manteram na mesma posição, assim como 36,36% dos pouco relevantes e 35,13% dos relevantes. Esta discrepância pode ser explicada pelo relaxamento em nosso critério durante a classificação manual, e pelo fato de ser uma base de dados sendo classificada por 2 pessoas diferentes, em que cada uma pode possuir uma interpretação levemente diferente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Por que não posso usar o próprio classificador para gerar mais amostras de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Não se pode usar o classificador para gerar mais amostras de treinamento, pois estas são feitas por seres humanos que tem uma interpretação do que significa ser relevante, irrelevante ou pouco relevante, enquanto o classificador apenas considera a frequência da palavra no tweet e no banco de dados. Assim qualquer variação na rigorosidade cria um efeito exacerbado no resultado do classificador, e ao usá-lo para gerar novos treinamentos, os próprios erros do classificador serão considerados corretos, fazendo com que ao longo do tempo ele irá desviar cada vez mais do padrão original, tendendo para um resultado completamente fora do escopo incial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propondo diferentes cenarios para utiliza o classificador Naive-Bayes:\n",
    "\n",
    "        Para melhorar o sistema de blacklist de sites para as redes de escolas, podemos adotar este método para banir sites de acordo com as palavras pesquisadas pelos alunos na internet.\n",
    "\n",
    "        Um cenário em que uma pessoa é suspeita de um crime, e há poucas provas e evidências, que mostram sua inocência ou culpa. Então, utilizamos o classificador para pegar as palavras mais usadas da pessoa em sites de pesquisa na internet, e passamos elas por um classificador treinado por palavras relevantes ao crime, para ver se a pessoa possui alguma pesquisa suspeita e que crie uma evidência contra ela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sugestões e explicações de melhorias reais para o nosso classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Como nossas mensagens são em inglês, a dupla negação seria errado gramaticalmente, não sendo necessária um tratamento para esta questão. Em questão ao tratamento de mensagens sarcásticas,seria muito difícil identificar estas, uma vez que nas redes sociais não há intonação de fala, um dos principais recursos para identificar sarcasmos.\n",
    "Uma melhoria direta seria ultilizar um algoritmo que usa a frequência e quantidade de emojis nos tweets para identificar sarcasmo, um exemplo e pesquisa direta seria: https://www.media.mit.edu/articles/an-algorithm-trained-on-emoji-knows-when-you-re-being-sarcastic-on-twitter/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Em relação ao plano de expansão de nosso projeto, poderíamos tentar ver se conseguiriamos tratar as mensagens sarcásticas, visto que elas podem ter um padrão de palavras como “lol”, “kekw” ou simplesmente um “haha”. Mas tendo observado que estes termos podem estar em mensagens que contém conteúdo não sarcástico, um estudo sobre as mensagens seria importante para evitar este erro, e aumentar a precisão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separações dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = pd.read_excel(filename, sheet_name = '6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construindo a funcao\n",
    "\n",
    "def classifier(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    X_train = list(X_train)\n",
    "    y_train = list(y_train)\n",
    "    X_test = list(X_test)\n",
    "    y_test = list(y_test)\n",
    "    \n",
    "    def separate_emoji(text): #separa emojis dos outros caracteres\n",
    "        return ''.join(' ' + char if char in UNICODE_EMOJI else char for char in text).strip() #caso seja um emoji, adiciona um espaco, caso nao seja, apenas retorna a letra.\n",
    "\n",
    "    chars = [\",\", \"'\", '\"', \".\", \"!\", \"?\", \";\", \":\", \"[\", \"]\",\"{\", \"}\", \"(\", \")\", \"#\", \"/\",  \"\\\\\", \"https\",\"+\", \"@\", \"*\", \"-\"] \n",
    "    word_count = dict()\n",
    "    total = 0 #total de palavras no banco de dados\n",
    "\n",
    "    \n",
    "\n",
    "    map(str.upper, y_train) #deixando tudo upper case\n",
    "\n",
    "      \n",
    "    for c in chars: #iterando a listad e cacarteres p/ remover\n",
    "        y_train =  [x if x != c else ' ' for x in y_train]\n",
    "\n",
    "    tweet_counter = 0 #contador para o word_count[word][X_train[tweet_counter]], conta o tweet que estamos na iteracao atual acessa a classificaca adequeada \n",
    "    \n",
    "    for piu in y_train: #esplitando em palavras e tweets separadaros \n",
    "        split_emoji = emoji.get_emoji_regexp().split(piu)\n",
    "        split_whitespace = [substr.split() for substr in split_emoji]\n",
    "        split = functools.reduce(operator.concat, split_whitespace)\n",
    "        tweet_counter += 1\n",
    "        for word in split:\n",
    "            word_count[word] = word_count.get(word, {'I':0, 'P':0, 'R':0}) #garantindo que  a palavra existe no dicionario, caso nao exista ela eh criada\n",
    "            word_count[word][X_train[tweet_counter - 1]] += 1 #incrementando o contador do valor correto #X_train\n",
    "            total += 1\n",
    "        \n",
    "\n",
    "    I = {word: word_count[word]['I'] for word in word_count if word_count[word]['I'] > 0} #I contem todas as palavras Irrelevantes, seu sum(I.values) == total de palavras Irrelevantes\n",
    "    P = {word: word_count[word]['P'] for word in word_count if word_count[word]['P'] > 0} #P contem todas as palavras Pouco relevantes, seu sum(P.values) == total de palavras Pouco relevantes\n",
    "    R = {word: word_count[word]['R'] for word in word_count if word_count[word]['R'] > 0} #R contem todas as palavras Relevantes, seu sum(R.values) == total de palavras Relevantes\n",
    "\n",
    "\n",
    "    tabela_relativa_R = pd.Series(R)\n",
    "\n",
    "    tabela_relativa_P = pd.Series(P)\n",
    "\n",
    "    tabela_relativa_I = pd.Series(I)\n",
    "\n",
    "\n",
    "\n",
    "    totalR = tabela_relativa_R.size #total de palavaras na categoria Relevante\n",
    "    totalP = tabela_relativa_P.size #total de palavaras na categoria Pouco Relevante\n",
    "    totalI = tabela_relativa_I.size #total de palavaras na categoria Irrelevante\n",
    "\n",
    "\n",
    "    #Calculando o P(P), P(R) e P(I)\n",
    "    probR = totalR/total\n",
    "\n",
    "    probP = totalP/total\n",
    "\n",
    "    probI = totalI/total\n",
    "    \n",
    "    #daqui em diante usar o X_test e y_test\n",
    "    l = [] #lista de classificacoes, mesma ordem da base test\n",
    "    for tweet in y_test: #iterando a base de dados\n",
    "\n",
    "        #inicializamos como 1 para nao dar erro na multiplicacao\n",
    "        probTweetR = 1  \n",
    "        probTweetP = 1\n",
    "        probTweetI = 1 \n",
    "\n",
    "\n",
    "        for c in chars: #iterando a listad e cacarteres p/ remover\n",
    "            y_test = tweet.replace(c, \" \") #trocando os caracteres por \" \"\n",
    "\n",
    "        #splitando os tweets em palavras e emojis separadamente e calculando a probalidade de cada palavra de ser cada categoria, fazendo a suavizacao de laplace\n",
    "        for word in separate_emoji(tweet).split(): \n",
    "\n",
    "            #Calculando o P(T|P), P(T|R) e P(T|I)\n",
    "            #pega o erro de palavras que nao existem em uma das tabelas\n",
    "            try: \n",
    "                probTweetR *= tabela_relativa_R[word]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try: \n",
    "                probTweetP *= tabela_relativa_P[word]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try: \n",
    "                probTweetI *= tabela_relativa_I[word]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        #calculando P(P|T), P(R|T), P(I|T)\n",
    "        probTweetR = probTweetR * probR\n",
    "\n",
    "        probTweetP = probTweetP * probP\n",
    "\n",
    "        probTweetI = probTweetI * probI\n",
    "\n",
    "        result = {\"R\":probTweetR,\"P\":probTweetP,\"I\": probTweetI} #dicionario para a comparacao dentro do MAX abaixo\n",
    "        l.append(max(result, key = result.get)) #compara os valores de r, p, i, e adiciona correta a lista L \n",
    "    \n",
    "    X_test = pd.DataFrame.from_dict(data = X_test)\n",
    "    X_test[\"Classificador\"] = l #adiciona a coluna classificacao a test, como a ordem eh a mesma, podemos adicionar.\n",
    "\n",
    "    #print(X_test)\n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda-Python\\lib\\site-packages\\ipykernel_launcher.py:87: RuntimeWarning: overflow encountered in longlong_scalars\n",
      "D:\\anaconda-Python\\lib\\site-packages\\ipykernel_launcher.py:82: RuntimeWarning: overflow encountered in longlong_scalars\n",
      "D:\\anaconda-Python\\lib\\site-packages\\ipykernel_launcher.py:92: RuntimeWarning: overflow encountered in longlong_scalars\n"
     ]
    }
   ],
   "source": [
    "# Definindo o grupo de variáveis independentes\n",
    "X = split[\"Classificação\"]\n",
    "\n",
    "# Definindo o grupo de variáveis dependentes\n",
    "y = split['tweets']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 250, train_size = 500, random_state = i)\n",
    "results = []\n",
    "for i in range(100):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 250, train_size = 500, random_state = i)\n",
    "\n",
    "    plsWork =  classifier(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    tab = (pd.crosstab(plsWork[0], plsWork.Classificador , normalize = True)*100).round(5)\n",
    "    results.append(tab.I.I + tab.P.P + tab.R.R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = pd.DataFrame(data = results)\n",
    "\n",
    "results = results.T\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.hist(results, bins = 100)   #np.arange(0, 100, 1))\n",
    "plt.title('Porcentagens de acerto por iteracao ')\n",
    "plt.xlabel('Porcentagens de acerto')\n",
    "plt.ylabel('Frequencia Absoluta')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discutindo o histograma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Ao construir um Classificador e considerar apenas uma divisão dos dados, estamos desconsiderando as outras possibilidades que dariam resultados diferentes da escolhida. Isto é ruim para o Classificador, uma vez que ao escolher um test train split que infla a taxa de sucesso, está mentindo sobre a real eficácia do Classificador. Podemos ver isso no histograma acima, em que o Classificador poderia ter a porcentagem de acerto de 49%, porém ela é a uma das menos frequentes, o que não representaria a verdadeira eficácia do Classificador. Seria adequado relatar que o Classificador tivesse algo em torno de 38-42% de porcentagem de acerto, uma vez que é uma parte do histograma que apresenta mais frequência em relação as outras porcentegens de acerto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
